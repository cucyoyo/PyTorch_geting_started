{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用其他kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<h1>hello jupyter-HTML<h2>\n",
    "<button>nihao</bottun>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing demo.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile demo.py\n",
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "# %load demo.py\n",
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 完整版的cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN (\n",
      "  (conv1): Sequential (\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (conv2): Sequential (\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  )\n",
      "  (out): Linear (1568 -> 10)\n",
      ")\n",
      "Please install sklearn for layer visualization\n",
      "Epoch:  0 | train loss: 2.3145 | test accuracy: 0.10\n",
      "Epoch:  0 | train loss: 0.5546 | test accuracy: 0.83\n",
      "Epoch:  0 | train loss: 0.5856 | test accuracy: 0.89\n",
      "Epoch:  0 | train loss: 0.1876 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.0599 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.1764 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0993 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.2207 | test accuracy: 0.95\n",
      "Epoch:  0 | train loss: 0.0373 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.0529 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.0269 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.0907 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.0968 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.3156 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0418 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1077 | test accuracy: 0.96\n",
      "Epoch:  0 | train loss: 0.0662 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1044 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.1355 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0436 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0275 | test accuracy: 0.97\n",
      "Epoch:  0 | train loss: 0.0153 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0443 | test accuracy: 0.98\n",
      "Epoch:  0 | train loss: 0.0082 | test accuracy: 0.98\n",
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision      # 数据库模块\\包括手写图的库\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "# Hyper Parameters\n",
    "EPOCH = 1           # 训练整批数据多少次, 为了节约时间, 我们只训练一次\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001          # 学习率\n",
    "DOWNLOAD_MNIST = False  # 如果你已经下载好了mnist数据就写上 Fasle\n",
    "\n",
    "# Mnist digits dataset\n",
    "if not(os.path.exists('./mnist/')) or not os.listdir('./mnist/'):\n",
    "    # not mnist dir or mnist is empyt dir\n",
    "    DOWNLOAD_MNIST = True\n",
    "\n",
    "\n",
    "# Mnist 手写数字（下载手写数字库）\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',    # 保存或者提取位置\n",
    "    train=True,  # true代表给出的是training_data;false代表给出的是test_data(大概有6万个)\n",
    "    # transform的过程会把图片每个像素点的值（0-255）压缩到(0-1)的区间\n",
    "    transform=torchvision.transforms.ToTensor(),    # 转换 PIL.Image or numpy.ndarray 成\n",
    "                                                    # torch.FloatTensor (C x H x W), 训练的时候 normalize 成 [0.0, 1.0] 区间\n",
    "    download=DOWNLOAD_MNIST,          # 没下载就下载, 下载了就不用再下了\n",
    ")\n",
    "\n",
    "# 画图显示一张图片\n",
    "# print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "# print(train_data.train_labels.size())               # (60000)\n",
    "# print(train_data.train_data[0].numpy())\n",
    "# plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "# plt.title('%i' % train_data.train_labels[0])\n",
    "# plt.show()\n",
    "\n",
    "# 批训练 50samples, 1 channel, 28x28 (50, 1, 28, 28)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# 提取test_data\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "\n",
    "# 为了节约时间, 我们测试时只测试前2000个\n",
    "test_x = Variable(torch.unsqueeze(test_data.test_data, dim=1), volatile=True).type(torch.FloatTensor)[:2000]/255.   # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)\n",
    "test_y = test_data.test_labels[:2000]\n",
    "\n",
    "#### 创建CNN网络\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 28, 28)\n",
    "            # 卷积层 过滤器 filter的高度为了提取属性\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height；输入高度\n",
    "                out_channels=16,    # n_filters：输出高度，filter个数，16个filter同时扫描，提取了16个特征，作为下一次的输入\n",
    "                kernel_size=5,      # filter size：filter的长和宽是5\n",
    "                stride=1,           # filter movement/step：filter扫描的跳度\n",
    "                padding=2,      # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "            ),      # output shape (16, 28, 28)\n",
    "            # 激励函数\n",
    "            nn.ReLU(),    # activation\n",
    "            # 池化层\n",
    "            nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, output shape (16, 14, 14)\n",
    "        )                                   # maxpool:2*2里面选取最大的；avaragepool：选取2*2里的平均值\n",
    "        self.conv2 = nn.Sequential(  # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  # output shape (32, 14, 14)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.MaxPool2d(2),  # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    # 将上述3位数据展平为二维数据\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # -1负责把所有维度放到一起\n",
    "        x = x.view(x.size(0), -1)   # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output, x\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)  # net architecture\n",
    "# print(x)\n",
    "\n",
    "#### 训练\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "\n",
    "# following function (plot_with_labels) is for visualization, can be ignored if not interested\n",
    "from matplotlib import cm\n",
    "try: from sklearn.manifold import TSNE; HAS_SK = True\n",
    "except: HAS_SK = False; print('Please install sklearn for layer visualization')\n",
    "def plot_with_labels(lowDWeights, labels):\n",
    "    plt.cla()\n",
    "    X, Y = lowDWeights[:, 0], lowDWeights[:, 1]\n",
    "    for x, y, s in zip(X, Y, labels):\n",
    "        c = cm.rainbow(int(255 * s / 9)); plt.text(x, y, s, backgroundcolor=c, fontsize=9)\n",
    "    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title('Visualize last layer'); plt.show(); plt.pause(0.01)\n",
    "\n",
    "plt.ion()\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):   # gives batch data, normalize x when iterate train_loader\n",
    "        b_x = Variable(x)   # batch x\n",
    "        b_y = Variable(y)   # batch y\n",
    "\n",
    "        output = cnn(b_x)[0]               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 50 == 0:\n",
    "            test_output, last_layer = cnn(test_x)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0], '| test accuracy: %.2f' % accuracy)\n",
    "            if HAS_SK:\n",
    "                # Visualization of trained flatten layer (T-SNE)\n",
    "                tsne = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "                plot_only = 500\n",
    "                low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])\n",
    "                labels = test_y.numpy()[:plot_only]\n",
    "                plot_with_labels(low_dim_embs, labels)\n",
    "plt.ioff()\n",
    "\n",
    "# print 10 predictions from test data\n",
    "test_output, _ = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
